_min_copier_version: "9.0.0"
_exclude:
  - ".git"
  - ".git/**"
  - ".github/workflows/template-smoke.yml"
  - "tests/test_runtime_assets.py"
  - "tests/test_template_smoke.py"
  - "tests/test_youtube_runtime.py"
_tasks:
  - mv specs/graph-sync/AGENTS.md AGENTS.md
  - |
      python - <<'PY'
      from pathlib import Path
      import shutil

      profiles = {{ profiles | tojson }}
      default_profile_dir = Path("profiles/default")
      seed_files = (
          "exports.toml.j2",
          "mappings/default.yarrrml.j2",
          "templates/20_organization.ttl.j2",
          "templates/20_website.ttl.j2",
          "templates/40_organization_postal_address.ttl.j2",
      )

      for profile in profiles:
          profile_dir = Path("profiles") / profile
          (profile_dir / "mappings").mkdir(parents=True, exist_ok=True)
          (profile_dir / "templates").mkdir(parents=True, exist_ok=True)
          (profile_dir / "postprocessors").mkdir(parents=True, exist_ok=True)

          if profile == "default":
              continue

          for rel_path in seed_files:
              src = default_profile_dir / rel_path
              dst = profile_dir / rel_path
              if dst.exists():
                  continue
              dst.parent.mkdir(parents=True, exist_ok=True)
              shutil.copy2(src, dst)
      PY
  - |
      python - <<'PY'
      from pathlib import Path

      api_key = {{ api_key | tojson }}
      sheets_service_account = {{ (sheets_service_account if source_type == "google_sheets" else "") | tojson }}

      # Keep secrets out of tracked config by writing them into local .env.
      escaped_service_account = sheets_service_account.replace("\n", "\\n")
      
      content = [
          f"WORDLIFT_API_KEY={api_key}",
          f"SHEETS_SERVICE_ACCOUNT={escaped_service_account}",
          "YOUTUBE_API_KEY=",
          "",
      ]
      Path(".env").write_text(chr(10).join(content), encoding="utf-8")
      PY
  - |
      python - <<'PY'
      from pathlib import Path
      import re

      pyproject_path = Path("pyproject.toml")
      if not pyproject_path.exists():
          raise SystemExit(0)

      project_dir_name = Path.cwd().name

      def normalize_project_name(raw: str) -> str:
          normalized = re.sub(r"[^a-z0-9._-]+", "-", raw.lower())
          normalized = re.sub(r"[-_.]+", "-", normalized).strip("-")
          if not normalized:
              normalized = "graph-sync-project"
          if normalized[0].isdigit():
              normalized = f"proj-{normalized}"
          return normalized

      pyproject_content = pyproject_path.read_text(encoding="utf-8")
      pyproject_content = re.sub(
          r'(?m)^name\s*=\s*"[^"]*"\s*$',
          f'name = "{normalize_project_name(project_dir_name)}"',
          pyproject_content,
          count=1,
      )
      pyproject_path.write_text(pyproject_content, encoding="utf-8")
      PY
  - |
      python - <<'PY'
      from pathlib import Path
      from urllib.error import HTTPError, URLError
      from urllib.parse import urlparse
      from urllib.request import Request, urlopen
      import json
      import re
      import sys

      api_key = {{ api_key | tojson }}
      validate_api_key = json.loads({{ validate_api_key | tojson | tojson }})
      package_name_file = Path(".package_name")
      fallback_package = "acme_graph_sync"

      def package_from_dataset_uri(dataset_uri: str) -> str:
          path = urlparse(dataset_uri).path
          parts = [p for p in re.split(r"[^a-zA-Z0-9]+", path.lower()) if p]
          base = "_".join(parts) if parts else "wordlift"
          if base[0].isdigit():
              base = f"pkg_{base}"
          return f"{base}_graph_sync"

      if not validate_api_key:
          package_name_file.write_text(fallback_package, encoding="utf-8")
          raise SystemExit(0)

      request = Request(
          "https://api.wordlift.io/accounts/me",
          headers={
              "Authorization": f"Key {api_key}",
              "Accept": "application/json",
          },
          method="GET",
      )

      try:
          with urlopen(request, timeout=10) as response:
              # Any 2xx response is considered valid.
              if 200 <= response.status < 300:
                  payload = json.loads(response.read().decode("utf-8"))
                  dataset_uri = str(payload.get("dataset_uri", "")).strip()
                  if not dataset_uri:
                      print(
                          "WordLift API key validation succeeded but dataset_uri is missing in response.",
                          file=sys.stderr,
                      )
                      raise SystemExit(1)
                  package_name_file.write_text(
                      package_from_dataset_uri(dataset_uri), encoding="utf-8"
                  )
                  raise SystemExit(0)
              print(
                  f"Unexpected response while validating WordLift API key: HTTP {response.status}",
                  file=sys.stderr,
              )
              raise SystemExit(1)
      except HTTPError as exc:
          if exc.code in (401, 403):
              print(
                  "WordLift API key validation failed (unauthorized). "
                  "Please check the key and run generation again.",
                  file=sys.stderr,
              )
          else:
              body = exc.read().decode("utf-8", errors="replace")[:300]
              print(
                  f"WordLift API key validation failed: HTTP {exc.code}. {body}",
                  file=sys.stderr,
              )
          raise SystemExit(1)
      except URLError as exc:
          # Keep generation usable when offline or API is temporarily unreachable.
          package_name_file.write_text(fallback_package, encoding="utf-8")
          print(
              f"Warning: could not validate WordLift API key due to network/API error: {exc}",
              file=sys.stderr,
          )
          raise SystemExit(0)
      except Exception as exc:
          package_name_file.write_text(fallback_package, encoding="utf-8")
          print(f"Warning: unexpected error during API key validation: {exc}", file=sys.stderr)
          raise SystemExit(0)
      PY
  - |
      python - <<'PY'
      from pathlib import Path
      import shutil

      old_package = "acme_kg"
      package_name_file = Path(".package_name")
      new_package = (
          package_name_file.read_text(encoding="utf-8").strip()
          if package_name_file.exists()
          else "acme_graph_sync"
      )
      package_name_file.unlink(missing_ok=True)

      if new_package == old_package:
          raise SystemExit(0)

      old_dir = Path("src") / old_package
      new_dir = Path("src") / new_package
      if old_dir.exists():
          if new_dir.exists():
              raise SystemExit(f"Cannot rename package: destination already exists: {new_dir}")
          shutil.move(str(old_dir), str(new_dir))

      suffixes = {".py", ".md", ".toml", ".yml", ".j2"}
      for file_path in Path(".").rglob("*"):
          if not file_path.is_file() or file_path.suffix not in suffixes:
              continue
          content = file_path.read_text(encoding="utf-8")
          if old_package not in content:
              continue
          file_path.write_text(content.replace(old_package, new_package), encoding="utf-8")
      PY

api_key:
  type: str
  secret: true
  default: ""
  help: WordLift API key (required)
  validator: "{% if not api_key or not api_key|trim %}api_key is required{% endif %}"

validate_api_key:
  type: bool
  default: true
  help: Validate API key against WordLift API during project generation
  when: "{{ false }}"

source_type:
  type: str
  help: Source of your page list
  choices:
    "Manual URL list": urls
    "Sitemap XML": sitemap
    "Google Sheets": google_sheets

urls:
  type: yaml
  help: Page URLs (YAML list)
  when: "{{ source_type == 'urls' }}"
  validator: "{% if source_type == 'urls' and (not urls or urls|length == 0) %}urls is required when source_type=urls{% endif %}"

sitemap_url:
  type: str
  help: Sitemap URL
  when: "{{ source_type == 'sitemap' }}"
  validator: "{% if source_type == 'sitemap' and (not sitemap_url or not sitemap_url|trim) %}sitemap_url is required when source_type=sitemap{% endif %}"

sitemap_url_pattern:
  type: str
  default: ""
  help: Sitemap URL filter pattern (optional regex)
  when: "{{ source_type == 'sitemap' }}"

sheets_url:
  type: str
  help: Google Sheets document URL
  when: "{{ source_type == 'google_sheets' }}"
  validator: "{% if source_type == 'google_sheets' and (not sheets_url or not sheets_url|trim) %}sheets_url is required when source_type=google_sheets{% endif %}"

sheets_name:
  type: str
  help: Google Sheets tab name
  when: "{{ source_type == 'google_sheets' }}"
  validator: "{% if source_type == 'google_sheets' and (not sheets_name or not sheets_name|trim) %}sheets_name is required when source_type=google_sheets{% endif %}"

sheets_service_account:
  type: str
  secret: true
  default: ""
  help: Google service account (JSON or path)
  when: "{{ source_type == 'google_sheets' }}"
  validator: "{% if source_type == 'google_sheets' and not sheets_service_account %}sheets_service_account is required when source_type=google_sheets{% endif %}"

overwrite:
  type: bool
  default: true
  help: Overwrite existing entities

concurrency:
  type: int
  default: 4
  help: Parallel import workers
  when: "{{ false }}"

ingest_loader:
  type: str
  default: web_scrape_api
  help: Ingestion loader
  choices:
    - web_scrape_api
    - simple
    - proxy
    - playwright
    - premium_scraper
    - passthrough
  when: "{{ false }}"

ingest_timeout_ms:
  type: int
  default: 120000
  help: Per-page timeout (milliseconds)
  when: "{{ false }}"

google_search_console:
  type: bool
  default: false
  help: Enable Google Search Console enrichment
  when: "{{ false }}"

profiles:
  type: yaml
  default:
    - default
  help: Profiles to generate (YAML list)
  validator: "{% if not profiles or profiles|length == 0 %}profiles must include at least one profile{% endif %}"
  when: "{{ false }}"

default_profile:
  type: str
  default: default
  help: Default profile
  validator: "{% if default_profile not in profiles %}default_profile must be one of the selected profiles{% endif %}"
  when: "{{ false }}"
